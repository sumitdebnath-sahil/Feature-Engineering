{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3adaf33-ab0c-4884-9468-3b0225942e07",
   "metadata": {},
   "source": [
    "1. What is a parameter?\n",
    "Ans. \n",
    "A parameter is a numerical value that describes a characteristic of a population in statistics.\n",
    "In simple terms:\n",
    "A parameter is a fixed, often unknown value that summarizes some aspect of a population (like its average or standard deviation).\n",
    "It is contrasted with a statistic, which is a value calculated from a sample (a subset of the population) and used to estimate the parameter.\n",
    "\n",
    "Examples:\n",
    "The mean height of all adult women in a country is a parameter.\n",
    "The proportion of voters who support a candidate in the entire population is a parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e96ecfa-e12a-4cef-9fab-b8ad66e4233b",
   "metadata": {},
   "source": [
    "2. What is correlation? What does negative correlation mean?\n",
    "Ans. Correlation is a statistical measure that describes the relationship between two variables. It tells you whether, and how strongly, changes in one variable are associated with changes in another.\n",
    "The most common measure is the Pearson correlation coefficient (r), which ranges from -1 to +1.\n",
    "\n",
    "A negative correlation means that as one variable increases, the other tends to decrease, and vice versa.\n",
    "\n",
    "Example:\n",
    "As exercise time increases, body weight may decrease → negative correlation.\n",
    "\n",
    "As number of missed classes increases, exam score tends to decrease → negative correlation.\n",
    "\n",
    "In numerical terms, a negative r value (like -0.7) indicates a strong inverse relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c284f75-924e-4b8d-b802-bd7ea0f49d55",
   "metadata": {},
   "source": [
    "3. Define Machine Learning.  What are the main components in Machine Learning?\n",
    "Ans. Machine Learning (ML) is a branch of artificial intelligence (AI) that focuses on building systems that can learn from data and make decisions or predictions without being explicitly programmed for every specific task.\n",
    "\n",
    "In simple terms, ML is about teaching computers to recognize patterns, improve from experience, and make data-driven decisions.\n",
    "\n",
    "Main Components of Machine Learning:\n",
    "\n",
    "1.Data:\n",
    "The foundation of machine learning.\n",
    "Includes inputs (features) and outputs (labels or targets).\n",
    "Example: Student scores (input) and pass/fail status (output).\n",
    "\n",
    "2.Model:\n",
    "A mathematical structure that makes predictions or decisions.\n",
    "Learns from data to identify patterns.\n",
    "Example: Linear regression model predicting house prices.\n",
    "\n",
    "3.Algorithm:\n",
    "The procedure used to train the model on data.\n",
    "Examples: Decision trees, support vector machines, neural networks.\n",
    "\n",
    "4.Training:\n",
    "The process of feeding data into the algorithm to help the model learn.\n",
    "The model adjusts its parameters to minimize errors.\n",
    "\n",
    "5.Evaluation:\n",
    "Measures how well the trained model performs using metrics like accuracy, precision, recall, etc.\n",
    "Usually done on a separate dataset (called a test set).\n",
    "\n",
    "6.Prediction:\n",
    "Using the trained model to make predictions on new or unseen data.\n",
    "\n",
    "7.Features:\n",
    "Individual measurable properties or characteristics used as input to the model.\n",
    "Example: Age, income, education level in a loan approval model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b962c167-ae90-41a9-9c58-0cff4b17e4be",
   "metadata": {},
   "source": [
    "4. How does loss value help in determining whether the model is good or not?\n",
    "Ans. In machine learning, the loss value is a quantitative measure of how well (or poorly) a model is performing. It represents the difference between the model’s predicted values and the actual (true) values.\n",
    "\n",
    "What is \"Loss\"?\n",
    "The loss is a single number that indicates how far the model's predictions are from the true results.\n",
    "A high loss means poor predictions.\n",
    "A low loss means the model is doing a good job.\n",
    "\n",
    "Why is Loss Important?\n",
    "Guides Training:\n",
    "The model uses the loss to update its internal parameters during training (using methods like gradient descent).\n",
    "The goal is to minimize the loss.\n",
    "\n",
    "Model Evaluation:\n",
    "Helps compare different models or configurations.\n",
    "The model with the lowest loss on the validation set is usually considered better.\n",
    "\n",
    "Early Detection of Overfitting/Underfitting:\n",
    "Training loss is low but validation loss is high → overfitting.\n",
    "Both losses are high → underfitting.\n",
    "\n",
    "Example:\n",
    "If you're training a model to predict housing prices:\n",
    "\n",
    "True price: $200,000\n",
    "\n",
    "Model predicts: $180,000\n",
    "\n",
    "Loss = function of the error (e.g., squared difference = (200,000 – 180,000)² = 400,000,000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3874e13c-aa8d-444a-b7df-b89050498008",
   "metadata": {},
   "source": [
    "5. What are continuous and categorical variables?\n",
    "Ans.\n",
    "Continuous Variables\n",
    "Definition: Variables that can take any numerical value within a range, including decimals or fractions.\n",
    "These variables are measurable.\n",
    "\n",
    "Examples:\n",
    "Height (e.g., 170.2 cm)\n",
    "Weight (e.g., 65.5 kg)\n",
    "Temperature (e.g., 36.6°C)\n",
    "Income (e.g., $45,000.75)\n",
    "\n",
    "Characteristics:\n",
    "Infinite possible values within a range\n",
    "Arithmetic operations (like mean, standard deviation) are meaningful\n",
    "\n",
    "Categorical Variables\n",
    "Definition: Variables that represent categories or groups. They can be labels or names and may or may not have a meaningful order.\n",
    "\n",
    "Examples:\n",
    "Gender (Male, Female, Other)\n",
    "Marital Status (Single, Married, Divorced)\n",
    "Blood Type (A, B, AB, O)\n",
    "Education Level (Primary, Secondary, Tertiary)\n",
    "\n",
    "Subtypes:\n",
    "Nominal (no order): e.g., Eye color (Blue, Green, Brown)\n",
    "Ordinal (has order): e.g., Satisfaction level (Low, Medium, High)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7575ef-09ba-4458-8c82-b6f86ba4a0d9",
   "metadata": {},
   "source": [
    "6. How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
    "Ans. Machine learning models typically require numerical input, so categorical variables must be converted into a numerical format before training a model.\n",
    "\n",
    "Common Techniques to Handle Categorical Variables:\n",
    "1. Label Encoding\n",
    "Converts each category into a unique number.\n",
    "\n",
    "Example: Color = {Red, Green, Blue} → Red=0, Green=1, Blue=2\n",
    "Best for: Ordinal data (where order matters, e.g., Low < Medium < High)\n",
    "\n",
    "2. One-Hot Encoding\n",
    "Creates a new binary column for each category.\n",
    "\n",
    "Example: Color = {Red, Green, Blue} becomes:\n",
    "Red   Green   Blue\n",
    " 1      0       0\n",
    " 0      1       0\n",
    " 0      0       1\n",
    "Best for: Nominal variables (no order)\n",
    "\n",
    "3. Ordinal Encoding\n",
    "Assigns numbers to categories based on order.\n",
    "Example: Satisfaction = {Low=1, Medium=2, High=3}\n",
    "Best for: Ordinal variables\n",
    "\n",
    "4. Binary Encoding\n",
    "Converts categories into binary code and splits into columns.\n",
    "Efficient for high-cardinality variables (with many categories).\n",
    "Example: Category “5” → Binary “101” → Three columns: [1, 0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453fe07e-bfb3-4a64-9f2e-9b0fd23a0f5d",
   "metadata": {},
   "source": [
    "7. What do you mean by training and testing a dataset?\n",
    "Ans. 1. Training a Dataset\n",
    "This is the process where a machine learning model learns from data.\n",
    "Training dataset: A portion of your data used to train the model.\n",
    "The model tries to find patterns, relationships, or rules in the data so it can make predictions or classifications.\n",
    "For example, in predicting house prices, the model learns how features like location, size, and number of bedrooms affect the price.\n",
    "\n",
    "2. Testing a Dataset\n",
    "This is the step where you evaluate the performance of the trained model.\n",
    "Testing dataset: A separate portion of the data not seen by the model during training.\n",
    "It checks how well the model can generalize to new, unseen data.\n",
    "Performance metrics like accuracy, precision, recall, or RMSE (root mean square error) are calculated here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf42912-38ff-4437-acf6-cc50a0966baa",
   "metadata": {},
   "source": [
    "8. What is sklearn.preprocessing?\n",
    "Ans. sklearn.preprocessing is a module in the scikit-learn (or sklearn) library in Python. It contains a set of tools to prepare and transform data before feeding it into a machine learning model.\n",
    "It helps with data cleaning, scaling, encoding, and normalization, which are essential for building good machine learning models.\n",
    "\n",
    "Common Tools in sklearn.preprocessing:\n",
    "1. StandardScaler\n",
    "What it does: Scales data to have mean = 0 and standard deviation = 1\n",
    "Why use it: Many ML algorithms perform better when features are on the same scale\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "2. MinMaxScaler\n",
    "What it does: Scales features to a fixed range, usually [0,1]\n",
    "Use case: When you want all features to be within a specific range.\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "3. LabelEncoder\n",
    "What it does: Converts categorical labels (like \"apple\", \"banana\") to numeric labels (like 0, 1)\n",
    "Use case: For encoding target variables (not features).\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "4. OneHotEncoder\n",
    "What it does: Converts categorical variables into binary (0/1) vectors\n",
    "Use case: For encoding categorical features (e.g., color: red, green, blue)\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "X_encoded = encoder.fit_transform(X)\n",
    "\n",
    "5. Binarizer\n",
    "What it does: Converts numeric values to 0 or 1 based on a threshold\n",
    "Use case: When you need binary classification or feature engineering\n",
    "\n",
    "from sklearn.preprocessing import Binarizer\n",
    "binarizer = Binarizer(threshold=0.5)\n",
    "X_bin = binarizer.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb4faba-a0b4-4871-9dd3-854ba57a7145",
   "metadata": {},
   "source": [
    "9. What is a Test set?\n",
    "Ans. A test set is a portion of your dataset that is kept separate from the training process and is used only to evaluate the final performance of a machine learning model.\n",
    "\n",
    "Purpose of the Test Set:\n",
    "To check how well your model performs on new, unseen data.\n",
    "To simulate real-world use, where the model has to make predictions on data it hasn’t seen before.\n",
    "To avoid overfitting — where the model learns the training data too well but fails to generalize.\n",
    "\n",
    "How It Works:\n",
    "split data into:\n",
    "Training set (usually 70–80%): Used to train the model.\n",
    "Test set (usually 20–30%): Used only once, after training, to measure accuracy, precision, recall, etc.\n",
    "After training the model, you run it on the test set to get performance metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6997e091-efdb-4b7b-8719-0249387f49ab",
   "metadata": {},
   "source": [
    "10. How do we split data for model fitting (training and testing) in Python? How do you approach a Machine Learning problem?\n",
    "Ans. In Python, the most common way to split data is using train_test_split() from scikit-learn.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Suppose X = features, y = target/labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X = feature variables (e.g., age, income)\n",
    "\n",
    "y = target variable (e.g., will buy: yes/no)\n",
    "\n",
    "test_size=0.2 means 20% of data goes to the test set\n",
    "\n",
    "random_state ensures the split is reproducible\n",
    "\n",
    "1. Define the Problem\n",
    "What are you trying to predict or classify?\n",
    "\n",
    "What is the business or research goal?\n",
    "\n",
    "2. Collect and Understand the Data\n",
    "Load the data (from CSV, SQL, etc.)\n",
    "\n",
    "Understand structure, types, missing values\n",
    "\n",
    "3. Preprocess the Data\n",
    "Handle missing values\n",
    "\n",
    "Encode categorical data (LabelEncoder or OneHotEncoder)\n",
    "\n",
    "Normalize or scale features (StandardScaler, MinMaxScaler)\n",
    "\n",
    "Split into train/test sets\n",
    "\n",
    "4. Choose a Model\n",
    "For classification: Logistic Regression, Decision Tree, Random Forest, etc.\n",
    "\n",
    "For regression: Linear Regression, Ridge, etc.\n",
    "5. Train the Model\n",
    "6. Evaluate the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba77c8b-024b-4538-be45-9968aa4a9523",
   "metadata": {},
   "source": [
    "11. Why do we have to perform EDA before fitting a model to the data?\n",
    "Ans. 1. Understand the Data\n",
    "EDA helps you learn what your data looks like — distributions, shapes, relationships, and outliers.\n",
    "\n",
    "You identify the types of variables (numerical, categorical) and their ranges or categories.\n",
    "\n",
    "Example: Is \"Age\" normally distributed? Are there unusual values like a 200-year-old person?\n",
    "\n",
    "2. Detect Missing or Invalid Data\n",
    "Missing values can break some models or reduce accuracy.\n",
    "\n",
    "You decide whether to fill, drop, or impute missing data.\n",
    "3. Spot Outliers and Anomalies\n",
    "Outliers can distort predictions, especially in models like linear regression.\n",
    "\n",
    "EDA helps decide whether to remove, cap, or transform those outliers.\n",
    "\n",
    "4. Choose the Right Features\n",
    "You can identify irrelevant, redundant, or highly correlated features.\n",
    "\n",
    "This helps in feature selection, reducing noise and improving performance.\n",
    "5. Decide on Preprocessing Steps\n",
    "Based on EDA, you know what transformations are needed:\n",
    "\n",
    "Scaling or normalizing?\n",
    "\n",
    "Encoding categorical features?\n",
    "\n",
    "Log-transforming skewed data?\n",
    "6. Understand Relationships\n",
    "Visuals like scatter plots or box plots help you spot patterns or group separations that models can learn from.\n",
    "\n",
    "For example: Does \"income\" increase with \"education level\"? Are certain classes more likely to churn?\n",
    "\n",
    "7. Avoid Garbage-In, Garbage-Out\n",
    "If your data is messy or misunderstood, your model will learn the wrong patterns, leading to poor generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ace86a-c203-4103-a4f1-a3b2920bfa2a",
   "metadata": {},
   "source": [
    "12. What is correlation?\n",
    "Ans. Correlation is a statistical measure that describes the relationship between two variables. It tells you whether, and how strongly, changes in one variable are associated with changes in another.\n",
    "The most common measure is the Pearson correlation coefficient (r), which ranges from -1 to +1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ca8971-7043-4081-afbb-a6db8d955380",
   "metadata": {},
   "source": [
    "13. What does negative correlation mean? \n",
    "Ans. A negative correlation means that as one variable increases, the other tends to decrease, and vice versa.\n",
    "\n",
    "Example:\n",
    "As exercise time increases, body weight may decrease → negative correlation.\n",
    "As number of missed classes increases, exam score tends to decrease → negative correlation.\n",
    "In numerical terms, a negative r value (like -0.7) indicates a strong inverse relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0928db85-8709-4d64-82dc-e6c703b75376",
   "metadata": {},
   "source": [
    "14. How can you find correlation between variables in Python?\n",
    "Ans.\n",
    "import pandas as pd\n",
    "\n",
    "# Load your data\n",
    "df = pd.read_csv('your_data.csv')\n",
    "\n",
    "# Get correlation matrix\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "print(correlation_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8173ca9d-f9e8-406a-b2b9-a086e2c82ff9",
   "metadata": {},
   "source": [
    "15. What is causation? Explain difference between correlation and causation with an example.\n",
    "Ans. Causation means that one variable directly affects another — a change in one causes a change in the other.\n",
    "Causation = Cause-and-Effect Relationship\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7547e6-75d7-47ec-8893-ced5c98dfc16",
   "metadata": {},
   "source": [
    "16. What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
    "Ans. An optimizer is an algorithm that adjusts the model's parameters (like weights) during training to minimize the loss (error).\n",
    "In simpler terms:\n",
    "Optimizers help the model learn by tweaking the model so it makes better predictions.\n",
    "Types of Optimizers (Mostly Used in Deep Learning)\n",
    "1. Gradient Descent (GD)\n",
    "Updates weights by calculating gradients over the whole dataset.\n",
    "\n",
    "Accurate, but slow for large datasets.\n",
    "2. Stochastic Gradient Descent (SGD)\n",
    "Updates weights for each training example.\n",
    "\n",
    "Faster but noisier updates (more fluctuation).\n",
    "3. Mini-Batch Gradient Descent\n",
    "A hybrid of GD and SGD.\n",
    "\n",
    "Uses a small batch of examples for each update.\n",
    "\n",
    "Most common in practice.\n",
    "4. Momentum\n",
    "Adds \"memory\" to SGD — remembers previous gradients to smooth the updates.\n",
    "\n",
    "Helps accelerate in the right direction, reduces oscillations.\n",
    "5. RMSprop (Root Mean Square Propagation)\n",
    "Adapts the learning rate for each parameter.\n",
    "\n",
    "Very effective in handling non-stationary objectives (good for RNNs and time series).\n",
    "6. Adam (Adaptive Moment Estimation)\n",
    "Combines Momentum + RMSprop\n",
    "\n",
    "Automatically adjusts learning rates\n",
    "\n",
    "Works well for most deep learning problems\n",
    "7. Adagrad\n",
    "Adjusts learning rate for each parameter based on past updates.\n",
    "\n",
    "Good for sparse data (e.g., text data), but learning rate may get too small over time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077c79b6-6a52-42f6-92ff-de1cd533fbc8",
   "metadata": {},
   "source": [
    "17. What is sklearn.linear_model ?\n",
    "Ans. sklearn.linear_model is a module in the scikit-learn library that provides linear models for regression and classification tasks in machine learning.\n",
    "1. Linear Regression\n",
    "Predicts a continuous numeric output.\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "2. Logistic Regression\n",
    "Used for binary or multi-class classification (e.g., spam or not).\n",
    "Outputs probabilities using the logistic (sigmoid) function.\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "3. Ridge Regression\n",
    "Linear regression with L2 regularization (penalty on large coefficients).\n",
    "Helps prevent overfitting.\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "ridge = Ridge(alpha=1.0)\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "4. Lasso Regression\n",
    "Linear regression with L1 regularization (can shrink some coefficients to zero).\n",
    "Useful for feature selection.\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "lasso = Lasso(alpha=0.1)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "5. ElasticNet\n",
    "Combines L1 and L2 regularization.\n",
    "Useful when you have many correlated features.\n",
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "enet = ElasticNet(alpha=0.1, l1_ratio=0.5)\n",
    "enet.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fa6ed7-3c28-4931-9c64-99cb75798db2",
   "metadata": {},
   "source": [
    "18. What does model.fit() do? What arguments must be given?\n",
    "Ans. model.fit() is the function used in scikit-learn (and other ML libraries) to train a machine learning model on your dataset.\n",
    "It \"fits\" the model to the data — that is, it learns the relationship between input features (X) and target labels (y).\n",
    "\n",
    "Calculates weights or parameters based on the training data.\n",
    "Minimizes the loss function (error) using optimization techniques (e.g., gradient descent).\n",
    "After fitting, the model can make predictions using model.predict()\n",
    "\n",
    "model.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae08a1b-d78c-4126-9c59-36129862e90a",
   "metadata": {},
   "source": [
    "19. What does model.predict() do? What arguments must be given?\n",
    "Ans. model.predict() is used after training your model with model.fit().\n",
    "It takes new input data (X) and returns predictions based on what the model has learned.\n",
    "In simple terms:\n",
    "It uses the trained model to make predictions on new data.\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)       # Train the model\n",
    "predictions = model.predict(X_test)  # Predict on new data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee56d4da-6e88-4697-a79a-5c4b364bf972",
   "metadata": {},
   "source": [
    "20. What are continuous and categorical variables?\n",
    "Ans. These are two types of variables commonly used in data analysis and machine learning.\n",
    "Continuous Variables\n",
    "Definition: Variables that can take any numerical value within a range, including decimals or fractions.\n",
    "These variables are measurable.\n",
    "\n",
    "Examples:\n",
    "Height (e.g., 170.2 cm)\n",
    "Weight (e.g., 65.5 kg)\n",
    "Temperature (e.g., 36.6°C)\n",
    "Income (e.g., $45,000.75)\n",
    "\n",
    "Characteristics:\n",
    "Infinite possible values within a range\n",
    "Arithmetic operations (like mean, standard deviation) are meaningful\n",
    "\n",
    "Categorical Variables\n",
    "Definition: Variables that represent categories or groups. They can be labels or names and may or may not have a meaningful order.\n",
    "\n",
    "Examples:\n",
    "Gender (Male, Female, Other)\n",
    "Marital Status (Single, Married, Divorced)\n",
    "Blood Type (A, B, AB, O)\n",
    "Education Level (Primary, Secondary, Tertiary)\n",
    "\n",
    "Subtypes:\n",
    "Nominal (no order): e.g., Eye color (Blue, Green, Brown)\n",
    "Ordinal (has order): e.g., Satisfaction level (Low, Medium, High)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059b2a3b-4e12-40d1-9bc8-4d0509aa0df4",
   "metadata": {},
   "source": [
    "21. What is feature scaling? How does it help in Machine Learning?\n",
    "Ans. Feature scaling is a technique used to normalize or standardize the range of independent variables (features) in your dataset.\n",
    "In simple terms:\n",
    "It adjusts the values of features to a common scale so that no feature dominates or biases the model.\n",
    "\n",
    "Many machine learning algorithms compute distances or gradients, and these can be skewed if one feature has much larger values than others.\n",
    "\n",
    "It helps by:\n",
    "Making training faster and more stable\n",
    "Improving model accuracy\n",
    "Ensuring features contribute fairly to predictions\n",
    "Avoiding bias toward large-valued features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1908adcf-719b-4dba-9e4d-0c8f0bc99771",
   "metadata": {},
   "source": [
    "22. How do we perform scaling in Python?\n",
    "Ans. scikit-learn provides built-in scalers to easily scale your features for machine learning.\n",
    "1. Min-Max Scaling (Normalization to [0, 1])\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(X_scaled)\n",
    "\n",
    "2. Standardization (Z-score: mean=0, std=1)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "print(X_scaled)\n",
    "\n",
    "3. Robust Scaling (Good for outliers)\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(X_scaled)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8117b069-8021-4c14-9350-0a4c73c4f3ca",
   "metadata": {},
   "source": [
    "23. What is sklearn.preprocessing?\n",
    "Ans. sklearn.preprocessing is a module in the scikit-learn library that provides tools for preprocessing data before feeding it into a machine learning model.\n",
    "In simple terms:\n",
    "It's where we find functions to clean, transform, and scale your data so it’s ready for modeling.\n",
    "\n",
    "Example: Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "X = np.array([[1.0, 200.0],\n",
    "              [2.0, 300.0],\n",
    "              [3.0, 400.0]])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(X_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ad1795-0cb0-46f6-88b3-89e8e57ca777",
   "metadata": {},
   "source": [
    "24. How do we split data for model fitting (training and testing) in Python?\n",
    "Ans. In machine learning, we split the data into:\n",
    "\n",
    "Training set: to train (fit) the model.\n",
    "\n",
    "Test set: to evaluate how well the model generalizes to new, unseen data.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b12767d-b8fc-41b2-b492-fc10e2bf0198",
   "metadata": {},
   "source": [
    "25. Explain data encoding?\n",
    "Ans. Data encoding is the process of converting categorical data (text labels or categories) into a numerical format that can be understood by machine learning models.\n",
    "Most ML models (like logistic regression, SVM, or neural networks) cannot handle text or labels like \"Male\", \"Blue\", \"Low\".\n",
    "\n",
    "Encoding transforms these into numbers so the model can process them."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
